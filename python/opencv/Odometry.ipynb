{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da036e46",
   "metadata": {},
   "source": [
    "### Visual Odometry using Monocular Camera\n",
    "Visual odmetry is used to determine motion (position and orientation) of the camera by analysing multiple sequence of images. It is different than the Visual SLAM as SLAM tackles two problems at once - figuring out where you are AND building a map of the environment. Visual odometry only concerns itself with tracking motion and doesn't attempt to create or maintain a map.\n",
    "\n",
    "#### Applications:\n",
    "* In Autonomous or self driving robots\n",
    "* Space Expolartion \n",
    "* Mapping environment \n",
    "* Localisation \n",
    "\n",
    "### Visual Odometry pipeline\n",
    "Image Squence  → Feature Detection  → Feature Matching  → Motion Estimation\n",
    "    \n",
    "#### triangulation \n",
    "Visual Odomentry triangulation is process of computing 3D position of a point in space by using multiple frames of the image, If you can see the same feature point in multiple images taken from different positions, you can figure out where that point lies in 3D space.It is essential for mapping the environment.\n",
    "\n",
    "### Camera matrix (Intrinsic parameters)\n",
    "It is a 3x3 matrix that encapsulates the inteernal properties of the camera, The process of determining these intrinsic parameters (and often distortion coefficients) is called camera calibration.\n",
    "![My Image](Images/image3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dc6fe8",
   "metadata": {},
   "source": [
    "### Epipolar Geometry\n",
    "Epipolar geometry describes geometric relation between two or more images of the same 3D scene like in stereo images. Epipolar Geometry requires two cameras (stereo vision) or a single camera moving through a path where the position 1 of the camera is considered as camera1 and position after time t is considered as camera2.\n",
    "\n",
    "* Epipolar Plane : it is a plane that is defined by the two camera centers and point X in space that is being considered \n",
    "\n",
    "* Epiline : a point seen in one image is seen as a line in another, these lines are called epilines. for example Xl point would be seen as a point by the left camera but as a line by the right camera.\n",
    "\n",
    "* Epipoles : Intersection of image plane (eR, eL) and the line joing the camera centers (baseline).\n",
    "![My Image](Images/image.png)\n",
    "\n",
    "* Essential Matrix : In monocular visual odometry, the Essential Matrix (E) encodes the relative rotation (R) and translation (t) between two camera positions — based on corresponding points in two images taken from slightly different viewpoints. As with any use of the essential matrix, it's assumed that the intrinsic parameters of the monocular camera are known.\n",
    "\n",
    "![My Image](Images/image2.png)\n",
    "\n",
    "* Fundamental Matrix : The Fundamental Matrix is a 3×3 matrix that relates corresponding points in two images taken from different viewpoints — without requiring the camera's intrinsic parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c640aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
