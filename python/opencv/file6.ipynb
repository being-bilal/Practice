{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35cbe159",
   "metadata": {},
   "source": [
    "### Image and Video Processing with OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18ee6056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43cc1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/bilal/.local/lib/python3.11/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "# Only displaying the orange blocks of the Rubik's cube\n",
    "# HSV = Hue(color), Saturation(intensity), value(brightness)\n",
    "path = 'assets/rubiks.mp4'\n",
    "cap = cv2.VideoCapture(path)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID') \n",
    "out = cv2.VideoWriter('assets/mask.avi', fourcc, 20.0, (640, 480)) \n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Video ended or cannot be read.\")\n",
    "        break\n",
    "    \n",
    "    frame_HSV = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) # converting the video from BGR channel to HSV channel\n",
    "    light_orange = np.array([5, 90, 20]) # lower bound of the orange color \n",
    "    dark_orange = np.array([10, 255, 255]) # upper bound of the orange color\n",
    "    \n",
    "    # .inRange() function turns the pixel between the given color range to white and the rest to black\n",
    "    mask = cv2.inRange(frame_HSV, light_orange, dark_orange) # creating a mask for the orange color\n",
    "    out.write(mask) \n",
    "    combined_image = cv2.bitwise_and(frame, frame, mask=mask) # applying the mask to the original frame\n",
    "    \n",
    "    # Blurring and sharpening the image (using convolution)\n",
    "    blurring_kernel = np.ones((5, 5), np.float32) \n",
    "    blurring_kernel /= 25  \n",
    "    blured_image = cv2.filter2D(combined_image, -1, blurring_kernel) # -1 means the output image will have the same depth as the input image\n",
    "    \n",
    "    # Gaussian blur (gaussian blur is a type of blurring that uses a Gaussian function)\n",
    "    # The kernel size must be odd and positive\n",
    "    gaussian_blur = cv2.GaussianBlur(blured_image, (5, 5), 0) # bigger the kernel size, more blurred the image will be \n",
    "    out.write(mask) \n",
    "    \n",
    "    # Sharpenning \n",
    "    sharpening_kernel = np.array([[0, -1, 0],\n",
    "                                  [-1, 5, -1],\n",
    "                                  [0, -1, 0]]) \n",
    "    sharpened_img = cv2.filter2D(gaussian_blur, -1, sharpening_kernel) # applying the sharpening kernel to the image\n",
    "    \n",
    "    cv2.imshow('Frame', gaussian_blur) \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break   \n",
    "    \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54456fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morphological operations\n",
    "# They are used to remove noise from binary image\n",
    "\n",
    "path = 'assets/rubiks.mp4'\n",
    "cap = cv2.VideoCapture(path)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Video ended or cannot be read.\")\n",
    "        break\n",
    "    \n",
    "    # Creatiing a binary mask\n",
    "    frame_HSV = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) # converting the video from BGR channel to HSV channel\n",
    "    light_orange = np.array([5, 90, 20]) # lower bound of the orange color \n",
    "    dark_orange = np.array([10, 255, 255]) # upper bound of the orange color\n",
    "    mask = cv2.inRange(frame_HSV, light_orange, dark_orange) # creating a mask for the orange color\n",
    "    \n",
    "    # Morphological operations\n",
    "    # Erosion: it uses convolution in which a kernel slides over the image such that a pixel in the \n",
    "    # original image (either 1 or 0) will be considered 1 only if all the pixels under the kernel is 1, otherwise it is eroded (made to zero).\n",
    "    kernel = np.ones((5,5))\n",
    "    erored_mask = cv2.erode(mask, kernel, iterations=1) # iterations defines the number of times the erosion process would occur\n",
    "    \n",
    "    # dilation : its the opposite of erosion, in this the kernel slides such that a pixel is 1 if atlest one pixel under the kernel is one else its 0\n",
    "    kernel = np.ones((3,3))\n",
    "    dilated_img = cv2.dilate(mask, kernel, iterations=1)\n",
    "    \n",
    "    \n",
    "    cv2.imshow('Frame', dilated_img) \n",
    "    if cv2.waitKey(15) & 0xFF == ord('q'):\n",
    "        break   \n",
    "    \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddfbf571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ended or cannot be read.\n"
     ]
    }
   ],
   "source": [
    "# Other morphological operations\n",
    "\n",
    "path = 'assets/rubiks.mp4'\n",
    "cap = cv2.VideoCapture(path)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Video ended or cannot be read.\")\n",
    "        break\n",
    "    \n",
    "    # Creatiing a binary mask\n",
    "    frame_HSV = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) # converting the video from BGR channel to HSV channel\n",
    "    light_orange = np.array([5, 90, 20]) # lower bound of the orange color \n",
    "    dark_orange = np.array([10, 255, 255]) # upper bound of the orange color\n",
    "    mask = cv2.inRange(frame_HSV, light_orange, dark_orange) # creating a mask for the orange color\n",
    "    \n",
    "    # opening: it is used to remove false positives in the image (small white regions in the backkground)\n",
    "    kernel = np.ones((3,3))\n",
    "    opened_img = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel) # it is the combination of erosion followed by dilation\n",
    "    \n",
    "    # closing: it is used to remove false negatives in the image (small black regions in the foreground)\n",
    "    closed_img = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel) \n",
    "    \n",
    "    cv2.imshow('Frame', closed_img) \n",
    "    if cv2.waitKey(15) & 0xFF == ord('q'):\n",
    "        break   \n",
    "    \n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5fd9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
